"""
VideoBot Pro - Tasks Package (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)
Celery –∑–∞–¥–∞—á–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–≥—Ä—É–∑–æ–∫
"""

import structlog

logger = structlog.get_logger(__name__)


try:
    from .download_tasks import (
        process_single_download,
        retry_failed_download,
        cleanup_expired_downloads,
        check_download_status,
        cancel_download_task,
    )
    logger.debug("Download tasks imported successfully")
except ImportError as e:
    logger.warning(f"Could not import download_tasks: {e}")
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏
    process_single_download = None
    retry_failed_download = None
    cleanup_expired_downloads = None
    check_download_status = None
    cancel_download_task = None

try:
    from .batch_tasks import (
        process_batch_download,
        create_batch_archive,
        retry_failed_batch,
        cleanup_expired_batches,
        check_batch_status,
    )
    logger.debug("Batch tasks imported successfully")
except ImportError as e:
    logger.warning(f"Could not import batch_tasks: {e}")
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏
    process_batch_download = None
    create_batch_archive = None
    retry_failed_batch = None
    cleanup_expired_batches = None
    check_batch_status = None

try:
    from .cleanup_tasks import (
        cleanup_old_files,
        cleanup_temp_files,
        cleanup_expired_cdn_links,
        vacuum_database,
        cleanup_analytics_events,
        health_check_task,
    )
    logger.debug("Cleanup tasks imported successfully")
except ImportError as e:
    logger.warning(f"Could not import cleanup_tasks: {e}")
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏
    cleanup_old_files = None
    cleanup_temp_files = None
    cleanup_expired_cdn_links = None
    vacuum_database = None
    cleanup_analytics_events = None
    health_check_task = None

try:
    from .analytics_tasks import (
        process_analytics_events,
        calculate_daily_stats,
        update_user_activity_stats,
        cleanup_old_analytics_events,
        generate_user_analytics_report,
        hourly_analytics_processing,
        daily_stats_calculation,
    )
    logger.debug("Analytics tasks imported successfully")
except ImportError as e:
    logger.warning(f"Could not import analytics_tasks: {e}")
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏
    process_analytics_events = None
    calculate_daily_stats = None
    update_user_activity_stats = None
    cleanup_old_analytics_events = None
    generate_user_analytics_report = None
    hourly_analytics_processing = None
    daily_stats_calculation = None

try:
    from .notification_tasks import (
        send_download_completion_notification,
        send_batch_completion_notification,
        send_premium_expiry_warning,
        send_broadcast_message,
        check_premium_expiry_notifications,
    )
    logger.debug("Notification tasks imported successfully")
except ImportError as e:
    logger.warning(f"Could not import notification_tasks: {e}")
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏
    send_download_completion_notification = None
    send_batch_completion_notification = None
    send_premium_expiry_warning = None
    send_broadcast_message = None
    check_premium_expiry_notifications = None

# –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ __all__ —Ç–æ–ª—å–∫–æ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∑–∞–¥–∞—á–∞–º–∏
__all__ = []

# –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–¥–∞—á –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
ALL_TASKS = [
    # Download tasks
    ('process_single_download', process_single_download),
    ('retry_failed_download', retry_failed_download),
    ('cleanup_expired_downloads', cleanup_expired_downloads),
    ('check_download_status', check_download_status),
    ('cancel_download_task', cancel_download_task),
    
    # Batch tasks
    ('process_batch_download', process_batch_download),
    ('create_batch_archive', create_batch_archive),
    ('retry_failed_batch', retry_failed_batch),
    ('cleanup_expired_batches', cleanup_expired_batches),
    ('check_batch_status', check_batch_status),
    
    # Cleanup tasks
    ('cleanup_old_files', cleanup_old_files),
    ('cleanup_temp_files', cleanup_temp_files),
    ('cleanup_expired_cdn_links', cleanup_expired_cdn_links),
    ('vacuum_database', vacuum_database),
    ('cleanup_analytics_events', cleanup_analytics_events),
    ('health_check_task', health_check_task),
    
    # Analytics tasks
    ('process_analytics_events', process_analytics_events),
    ('calculate_daily_stats', calculate_daily_stats),
    ('update_user_activity_stats', update_user_activity_stats),
    ('cleanup_old_analytics_events', cleanup_old_analytics_events),
    ('generate_user_analytics_report', generate_user_analytics_report),
    ('hourly_analytics_processing', hourly_analytics_processing),
    ('daily_stats_calculation', daily_stats_calculation),
    
    # Notification tasks
    ('send_download_completion_notification', send_download_completion_notification),
    ('send_batch_completion_notification', send_batch_completion_notification),
    ('send_premium_expiry_warning', send_premium_expiry_warning),
    ('send_broadcast_message', send_broadcast_message),
    ('check_premium_expiry_notifications', check_premium_expiry_notifications),
]

# –î–æ–±–∞–≤–ª—è–µ–º –≤ __all__ —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–¥–∞—á–∏
available_tasks = []
unavailable_tasks = []

for task_name, task_obj in ALL_TASKS:
    if task_obj is not None:
        __all__.append(task_name)
        available_tasks.append(task_name)
    else:
        unavailable_tasks.append(task_name)

# –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–∞–¥–∞—á –ø–æ —Ç–∏–ø–∞–º –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
DOWNLOAD_TASKS = [name for name, obj in ALL_TASKS[:5] if obj is not None]
BATCH_TASKS = [name for name, obj in ALL_TASKS[5:10] if obj is not None]
CLEANUP_TASKS = [name for name, obj in ALL_TASKS[10:16] if obj is not None]
ANALYTICS_TASKS = [name for name, obj in ALL_TASKS[16:23] if obj is not None]
NOTIFICATION_TASKS = [name for name, obj in ALL_TASKS[23:] if obj is not None]

# –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –¥–ª—è Celery Beat
PERIODIC_TASKS = {
    # –û—á–∏—Å—Ç–∫–∞ –∫–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤
    'cleanup-old-files': {
        'task': 'worker.tasks.cleanup_tasks.cleanup_old_files',
        'schedule': 6.0 * 60 * 60,  # 6 hours
        'enabled': cleanup_old_files is not None,
    },
    
    # –û—á–∏—Å—Ç–∫–∞ temp —Ñ–∞–π–ª–æ–≤ –∫–∞–∂–¥—ã–π —á–∞—Å
    'cleanup-temp-files': {
        'task': 'worker.tasks.cleanup_tasks.cleanup_temp_files', 
        'schedule': 60.0 * 60,  # 1 hour
        'enabled': cleanup_temp_files is not None,
    },
    
    # –û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–µ–∫—à–∏—Ö CDN —Å—Å—ã–ª–æ–∫ –∫–∞–∂–¥—ã–µ 2 —á–∞—Å–∞
    'cleanup-expired-cdn': {
        'task': 'worker.tasks.cleanup_tasks.cleanup_expired_cdn_links',
        'schedule': 2.0 * 60 * 60,  # 2 hours
        'enabled': cleanup_expired_cdn_links is not None,
    },
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–Ω–µ–≤–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ 00:30
    'generate-daily-stats': {
        'task': 'worker.tasks.analytics_tasks.daily_stats_calculation',
        'schedule': {
            'hour': 0,
            'minute': 30,
        },
        'enabled': daily_stats_calculation is not None,
    },
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π –∫–∞–∂–¥—ã–µ 10 –º–∏–Ω—É—Ç
    'process-analytics': {
        'task': 'worker.tasks.analytics_tasks.hourly_analytics_processing',
        'schedule': 10.0 * 60,  # 10 minutes
        'enabled': hourly_analytics_processing is not None,
    },
    
    # Health check –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
    'health-check': {
        'task': 'worker.tasks.cleanup_tasks.health_check_task',
        'schedule': 5.0 * 60,  # 5 minutes
        'enabled': health_check_task is not None,
    },
    
    # –û—á–∏—Å—Ç–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ –≤ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ –≤ 03:00
    'vacuum-database': {
        'task': 'worker.tasks.cleanup_tasks.vacuum_database',
        'schedule': {
            'hour': 3,
            'minute': 0,
            'day_of_week': 0,  # Sunday
        },
        'enabled': vacuum_database is not None,
    },
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–µ—á–µ–Ω–∏—è Premium –ø–æ–¥–ø–∏—Å–æ–∫ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ –≤ 09:00
    'check-premium-expiry': {
        'task': 'worker.tasks.notification_tasks.check_premium_expiry_notifications',
        'schedule': {
            'hour': 9,
            'minute': 0,
        },
        'enabled': check_premium_expiry_notifications is not None,
    },
}

# –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏
ACTIVE_PERIODIC_TASKS = {
    name: config for name, config in PERIODIC_TASKS.items() 
    if config.get('enabled', False)
}

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ä–æ—É—Ç–∏–Ω–≥–∞ –∑–∞–¥–∞—á
TASK_ROUTES = {
    # –ö—Ä–∏—Ç–∏—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ –Ω–∞ –±—ã—Å—Ç—Ä—É—é –æ—á–µ—Ä–µ–¥—å
    'worker.tasks.download_tasks.*': {'queue': 'downloads'},
    'worker.tasks.batch_tasks.*': {'queue': 'downloads'},
    'worker.tasks.notification_tasks.*': {'queue': 'notifications'},
    
    # –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –Ω–∞ –º–µ–¥–ª–µ–Ω–Ω—É—é –æ—á–µ—Ä–µ–¥—å  
    'worker.tasks.cleanup_tasks.*': {'queue': 'cleanup'},
    'worker.tasks.analytics_tasks.*': {'queue': 'analytics'},
}

# –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∑–∞–¥–∞—á
TASK_PRIORITIES = {
    'high': 9,
    'normal': 5, 
    'low': 1,
}

def get_task_priority(user_type: str) -> int:
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∑–∞–¥–∞—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    priority_map = {
        'admin': TASK_PRIORITIES['high'],
        'premium': TASK_PRIORITIES['high'], 
        'trial': TASK_PRIORITIES['normal'],
        'free': TASK_PRIORITIES['low'],
    }
    return priority_map.get(user_type, TASK_PRIORITIES['normal'])

def get_available_tasks() -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∑–∞–¥–∞—á –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
    return {
        'download': DOWNLOAD_TASKS,
        'batch': BATCH_TASKS,
        'cleanup': CLEANUP_TASKS,
        'analytics': ANALYTICS_TASKS,
        'notifications': NOTIFICATION_TASKS,
        'total_available': len(available_tasks),
        'total_unavailable': len(unavailable_tasks),
    }

def get_task_by_name(task_name: str):
    """
    –ü–æ–ª—É—á–∏—Ç—å –æ–±—ä–µ–∫—Ç –∑–∞–¥–∞—á–∏ –ø–æ –∏–º–µ–Ω–∏
    
    Args:
        task_name: –ò–º—è –∑–∞–¥–∞—á–∏
        
    Returns:
        –û–±—ä–µ–∫—Ç –∑–∞–¥–∞—á–∏ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
    """
    return globals().get(task_name)

def is_task_available(task_name: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏
    
    Args:
        task_name: –ò–º—è –∑–∞–¥–∞—á–∏
        
    Returns:
        True –µ—Å–ª–∏ –∑–∞–¥–∞—á–∞ –¥–æ—Å—Ç—É–ø–Ω–∞
    """
    return task_name in available_tasks

def get_tasks_info() -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–¥–∞—á–∞—Ö"""
    return {
        'package_version': '2.1.0',
        'total_tasks_defined': len(ALL_TASKS),
        'available_tasks': len(available_tasks),
        'unavailable_tasks': len(unavailable_tasks),
        'available_task_names': available_tasks,
        'unavailable_task_names': unavailable_tasks,
        'periodic_tasks_available': len(ACTIVE_PERIODIC_TASKS),
        'periodic_tasks_total': len(PERIODIC_TASKS),
        'task_categories': {
            'download': len(DOWNLOAD_TASKS),
            'batch': len(BATCH_TASKS),
            'cleanup': len(CLEANUP_TASKS),
            'analytics': len(ANALYTICS_TASKS),
            'notifications': len(NOTIFICATION_TASKS),
        }
    }

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∑–∞–¥–∞—á–∞–º–∏
def submit_download_task(url: str, user_id: int, **kwargs):
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–¥–∞—á—É –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ"""
    if process_single_download is None:
        raise RuntimeError("Download tasks not available")
    
    # –ó–¥–µ—Å—å –±—É–¥–µ—Ç –ª–æ–≥–∏–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á–∏ –≤ –ë–î –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Celery
    # –ü–æ–∫–∞ —á—Ç–æ –∑–∞–≥–ª—É—à–∫–∞
    logger.info(f"Would submit download task for URL: {url}")
    return {"task_id": "mock_task_id", "status": "pending"}

def submit_batch_task(urls: list, user_id: int, **kwargs):
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å batch –∑–∞–¥–∞—á—É"""
    if process_batch_download is None:
        raise RuntimeError("Batch tasks not available")
    
    logger.info(f"Would submit batch task for {len(urls)} URLs")
    return {"batch_id": "mock_batch_id", "status": "pending"}

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏
logger.info(
    "Tasks package loaded",
    available_tasks=len(available_tasks),
    unavailable_tasks=len(unavailable_tasks),
    periodic_tasks=len(ACTIVE_PERIODIC_TASKS)
)

if unavailable_tasks:
    logger.warning(
        "Some tasks are not available",
        unavailable_tasks=unavailable_tasks[:5]  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
    )

if available_tasks:
    logger.info(
        "Available task categories",
        download=len(DOWNLOAD_TASKS),
        batch=len(BATCH_TASKS),
        cleanup=len(CLEANUP_TASKS),
        analytics=len(ANALYTICS_TASKS),
        notifications=len(NOTIFICATION_TASKS)
    )

print(f"üì¶ VideoBot Pro Tasks v2.1.0 - {len(available_tasks)}/{len(ALL_TASKS)} tasks available")